{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72561ee9-9bf3-42be-8f0b-001aad9dfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Dossier contenant les fichiers CSV\n",
    "folder_path = \"consolide\"  \n",
    "\n",
    "# Fonction pour cr√©er un format JSON √† partir des donn√©es CSV\n",
    "def convert_csv_to_json(file_path):\n",
    "    try:\n",
    "        # Charger le fichier CSV\n",
    "       # df = pd.read_csv(file_path, sep=';')\n",
    "        df = pd.read_csv(file_path, sep=';', encoding=\"utf-8\")\n",
    "\n",
    "        # Reconstituer le texte complet en s'assurant que tous les tokens sont des cha√Ænes\n",
    "        tokens = df[\"Token\"].fillna(\"\").astype(str).tolist()  # Remplacer les NaN par une cha√Æne vide et convertir en str\n",
    "       # full_text = \" \".join(tokens)\n",
    "        #full_text = \" \".join(df[\"Token\"].dropna().astype(str)).strip()\n",
    "        # Reconstituer le texte complet sans espaces superflus ni sauts de ligne\n",
    "        full_text = \" \".join(df[\"Token\"].dropna().astype(str)).replace(\"\\n\", \"\").strip()\n",
    "\n",
    "        # Statistiques pour le fichier\n",
    "        num_tokens = len(tokens)\n",
    "        num_annotations = 0\n",
    "        num_quaero_annotations = 0\n",
    "\n",
    "        # Pr√©parer les annotations\n",
    "        annotations = []\n",
    "        for i, row in df.iterrows():\n",
    "            token = str(row[\"Token\"])  # Convertir en cha√Æne de caract√®res\n",
    "            label = row[\"Label_Maj\"]\n",
    "            quaero_label = row[\"Quaero_Maj\"] if pd.notna(row[\"Quaero_Maj\"]) else None\n",
    "\n",
    "            # Si l'annotation est pr√©sente\n",
    "            if pd.notna(label):\n",
    "                # Calculer la position du token dans le texte complet\n",
    "                start = full_text.find(token)\n",
    "                end = start + len(token)\n",
    "\n",
    "                # Ajouter l'annotation au format requis\n",
    "                annotation = {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"tag_id\": str(uuid.uuid4()),  # Tag ID unique\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"example_id\": str(uuid.uuid4()),\n",
    "                    \"tag_name\": label,\n",
    "                    \"value\": token,\n",
    "                    \"correct\": None,\n",
    "                    \"human_annotations\": [],\n",
    "                    \"model_annotations\": []\n",
    "                }\n",
    "\n",
    "                # Si c'est une entit√© de type \"LOC\", v√©rifier si Quaero est aussi disponible\n",
    "                if label == \"LOC\" and quaero_label:\n",
    "                    annotation[\"tag_name\"] = f\"LOC, {quaero_label}\"  # Ajouter Quaero √† l'annotation\n",
    "                    num_quaero_annotations += 1\n",
    "\n",
    "                annotations.append(annotation)\n",
    "                num_annotations += 1\n",
    "\n",
    "        # Pr√©parer l'exemple\n",
    "        example = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"content\": full_text,\n",
    "            \"metadata\": {},\n",
    "            \"annotations\": annotations\n",
    "        }\n",
    "\n",
    "        # Suivi des statistiques pour l'affichage\n",
    "        print(f\"üìÇ Fichier : {file_path}\")\n",
    "        print(f\"   üîπ Nombre de tokens : {num_tokens}\")\n",
    "        print(f\"   üîπ Nombre d'annotations : {num_annotations}\")\n",
    "        print(f\"   üîπ Nombre d'annotations Quaero : {num_quaero_annotations}\")\n",
    "        \n",
    "        # Retourner les donn√©es au format JSON\n",
    "        return {\"examples\": [example]}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur avec {file_path} : {e}\")\n",
    "        return None\n",
    "\n",
    "# Liste pour accumuler les donn√©es JSON de tous les fichiers\n",
    "all_data = {\"examples\": []}\n",
    "\n",
    "# Parcourir tous les fichiers du dossier\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):  # V√©rifie que c'est un fichier CSV\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Convertir le fichier CSV en format JSON\n",
    "        json_data = convert_csv_to_json(file_path)\n",
    "        \n",
    "        if json_data:\n",
    "            # Ajouter les donn√©es au fichier JSON principal\n",
    "            all_data[\"examples\"].extend(json_data[\"examples\"])\n",
    "\n",
    "# Sauvegarder tous les fichiers JSON dans un fichier de sortie unique\n",
    "output_file_path = \"combined_data_output.json\"\n",
    "with open(output_file_path, 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(all_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Tous les fichiers ont √©t√© combin√©s et sauvegard√©s sous '{output_file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
